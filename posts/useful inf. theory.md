---
label: Useful (information theory)
data:
  youtube: <img src="/assets/icons/youtube.svg" width=20 />

---

### Good materials:

[{{ youtube }} best 10 mins - Entropy, Cross-Entropy and KL-Divergence](https://youtu.be/ErfnhcEV1O8)


Excellent explanaiton of binary vs categorical cross-entropy:
- https://datascience.stackexchange.com/q/9302/136526


[{{ youtube }} some intuition about KL-divergence (not very robust)](https://youtu.be/SxGYPqCgJWM)




---

<br />

### more:

- https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e

